
# Lecture 1:
### Computational Problem:
-> Inputs 
-> Outputs
and by discrete math computation is the act of mapping these inputs to their respective outputs, thereby establishing a binary relationship between them. The relationship generated is a bipartite graph.

- General problems that have arbitrarily sized inputs and our algorithms needs to solve them, and minimize the time and memory used for them.

### Efficiency of an Algorithm:

What the efficiency of algorithm depends on:
-> The size of the dataset
-> The specification of the device where it is used *

-> * Since the time varies from machine to machine so we do not count the time, instead we try to find an abstract notation of that algorithm called the "asymptotic analysis" represented using "asymptotic notation".

### Asymptotic Notations:
-> O(.): Upper Bound
-> $\ohm$(.): Lower Bound
-> $\theta$(.): Both Upper and lower bounds

O(1) : Constant time algorithm
$\theta$(n) : Linear
$\theta$(log n) : logarithmic
$\theta$(nlogn) : n x log n
$\theta$($n^2$) : n squared algorithm
$\theta$($2^n$) : Exponential algorithm

### Data Structure:
"Already covered, although will be covered again"
Ways of storing a non constant amount of information to make operations on the data faster.

# Lecture 2

-> Sequence data structure:
-> Approaches in using data Structures:
- Array Based approach
- Pointer Based

**Array**: A linear data structure that allows us to store data in contiguous memory blocks and access them in constant time. Insertion and deletion takes constant time as well while traversal takes linear time.

